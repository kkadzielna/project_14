{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "dp = pd.read_csv(\"../screenTime/maps-synthetic-data-v1.1.csv\")\n",
    "dic = pd.read_csv('../screenTime/synthetic_data_dictionary.csv')\n",
    "dp = pd.DataFrame(dp)\n",
    "dic = pd.DataFrame(dic)\n",
    "\n",
    "# Create table for missing data analysis\n",
    "def draw_missing_data_table(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    \n",
    "    #change the index name\n",
    "    missing_data.reset_index(inplace = True)\n",
    "    missing_data = missing_data.rename(columns = {'index':'variables'})\n",
    "    return missing_data\n",
    "\n",
    "# drop variable which has missing values more than 80% \n",
    "# df.loc[df[‘column name’] condition]\n",
    "def drop_missing_75percent_value(df, dic):\n",
    "    missing_table = draw_missing_data_table(df)\n",
    "    droped_data = missing_table.loc[missing_table['Percent']>0.80]\n",
    "    var = list(droped_data['variables'])\n",
    "    df = df.drop(var,axis=1)\n",
    "    dic = dic[~dic['Variable Name'].isin(var)]\n",
    "    return df, dic\n",
    "\n",
    "dp, dic = drop_missing_75percent_value(dp, dic)\n",
    "draw_missing_data_table(dp)\n",
    "\n",
    "# Aged 16 data\n",
    "# get the train data, where the variables related to 'Aged 198 months' and 'Aged around 15.5 years' children\n",
    "aged_16_var = dic.loc[(dic['Age of child at administration']=='Aged 198 months') |(dic['Age of child at administration']=='Aged around 15.5 years') ]\n",
    "X = dp[list(aged_16_var['Variable Name'])]\n",
    "aged_18_var = dic.loc[dic['Age of child at administration']=='Aged around 17.5 years']\n",
    "Y = dp[list(aged_18_var['Variable Name'])]\n",
    "\n",
    "# description of variables\n",
    "description_X = aged_16_var[['Variable Name', 'Variable Description']]\n",
    "description_Y = aged_18_var[['Variable Name', 'Variable Description']]\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# list of varaibles which has object type\n",
    "type_label_object = X.select_dtypes(['object']).columns\n",
    "variable_name = list(type_label_object)\n",
    "# set type of object variable to 'categroy'\n",
    "X[variable_name] = X[variable_name].astype('category')\n",
    "#convert category to numbers[0,1,2,3...], and NA->-1\n",
    "for i in X.columns:\n",
    "    if str(X[i].dtype)=='category':\n",
    "        X[i] = pd.factorize(X[i])[0]\n",
    "        \n",
    "# Turn -1 back to NA\n",
    "X[X==-1] = np.nan\n",
    "\n",
    "Y['has_dep_diag'] = Y['has_dep_diag'].astype('category')\n",
    "Y['has_dep_diag'] = pd.factorize(Y['has_dep_diag'])[0]\n",
    "Y[Y==-1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alon_week</th>\n",
       "      <th>alon_wend</th>\n",
       "      <th>anx_band_15</th>\n",
       "      <th>child_bull</th>\n",
       "      <th>comp_week</th>\n",
       "      <th>comp_wend</th>\n",
       "      <th>dep_band_15</th>\n",
       "      <th>draw_week</th>\n",
       "      <th>draw_wend</th>\n",
       "      <th>exercise</th>\n",
       "      <th>...</th>\n",
       "      <th>talk_phon_week</th>\n",
       "      <th>talk_phon_wend</th>\n",
       "      <th>text_wend</th>\n",
       "      <th>tran_week</th>\n",
       "      <th>tran_wend</th>\n",
       "      <th>tv_week</th>\n",
       "      <th>tv_wend</th>\n",
       "      <th>weight_16</th>\n",
       "      <th>work_week</th>\n",
       "      <th>work_wend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.294132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.812426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.270030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.075832</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13732</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13733</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.732913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13734 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alon_week  alon_wend  anx_band_15  child_bull  comp_week  comp_wend  \\\n",
       "0            0.0        0.0          0.0         0.0        0.0        0.0   \n",
       "1            NaN        NaN          NaN         NaN        NaN        NaN   \n",
       "2            NaN        NaN          NaN         NaN        NaN        NaN   \n",
       "3            NaN        NaN          NaN         NaN        NaN        NaN   \n",
       "4            0.0        1.0          1.0         0.0        0.0        1.0   \n",
       "...          ...        ...          ...         ...        ...        ...   \n",
       "13729        NaN        NaN          NaN         NaN        NaN        NaN   \n",
       "13730        0.0        1.0          NaN         0.0        0.0        0.0   \n",
       "13731        0.0        0.0          2.0         0.0        0.0        0.0   \n",
       "13732        2.0        0.0          NaN         0.0        2.0        0.0   \n",
       "13733        NaN        NaN          1.0         NaN        NaN        NaN   \n",
       "\n",
       "       dep_band_15  draw_week  draw_wend  exercise  ...  talk_phon_week  \\\n",
       "0              0.0        0.0        0.0       0.0  ...             0.0   \n",
       "1              NaN        NaN        NaN       NaN  ...             NaN   \n",
       "2              NaN        NaN        NaN       NaN  ...             NaN   \n",
       "3              NaN        NaN        NaN       NaN  ...             NaN   \n",
       "4              1.0        0.0        0.0       1.0  ...             0.0   \n",
       "...            ...        ...        ...       ...  ...             ...   \n",
       "13729          NaN        NaN        NaN       NaN  ...             NaN   \n",
       "13730          NaN        1.0        1.0       1.0  ...             0.0   \n",
       "13731          3.0        1.0        1.0       0.0  ...             1.0   \n",
       "13732          NaN        2.0        1.0       0.0  ...             0.0   \n",
       "13733          0.0        NaN        NaN       NaN  ...             NaN   \n",
       "\n",
       "       talk_phon_wend  text_wend  tran_week  tran_wend  tv_week  tv_wend  \\\n",
       "0                 0.0        0.0        0.0        0.0      0.0      0.0   \n",
       "1                 NaN        NaN        NaN        NaN      NaN      NaN   \n",
       "2                 NaN        NaN        NaN        NaN      NaN      NaN   \n",
       "3                 NaN        NaN        NaN        NaN      NaN      NaN   \n",
       "4                 1.0        1.0        0.0        0.0      0.0      1.0   \n",
       "...               ...        ...        ...        ...      ...      ...   \n",
       "13729             NaN        NaN        NaN        NaN      NaN      NaN   \n",
       "13730             1.0        0.0        0.0        0.0      1.0      1.0   \n",
       "13731             0.0        3.0        1.0        1.0      1.0      1.0   \n",
       "13732             0.0        3.0        0.0        0.0      3.0      2.0   \n",
       "13733             NaN        NaN        NaN        NaN      NaN      NaN   \n",
       "\n",
       "       weight_16  work_week  work_wend  \n",
       "0      59.294132        0.0        0.0  \n",
       "1            NaN        NaN        NaN  \n",
       "2            NaN        NaN        NaN  \n",
       "3      49.812426        NaN        NaN  \n",
       "4      62.270030        1.0        1.0  \n",
       "...          ...        ...        ...  \n",
       "13729        NaN        NaN        NaN  \n",
       "13730        NaN        1.0        1.0  \n",
       "13731  58.075832        2.0        2.0  \n",
       "13732        NaN        2.0        1.0  \n",
       "13733  70.732913        NaN        NaN  \n",
       "\n",
       "[13734 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep_score</th>\n",
       "      <th>has_dep_diag</th>\n",
       "      <th>panic_score</th>\n",
       "      <th>prim_diag</th>\n",
       "      <th>secd_diag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13730</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13731</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13733</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13734 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dep_score  has_dep_diag  panic_score  prim_diag  secd_diag\n",
       "0            0.0           0.0          0.0        0.0        0.0\n",
       "1            NaN           NaN          NaN        NaN        NaN\n",
       "2            NaN           NaN          NaN        NaN        NaN\n",
       "3            NaN           NaN          NaN        NaN        NaN\n",
       "4            NaN           NaN          NaN        NaN        NaN\n",
       "...          ...           ...          ...        ...        ...\n",
       "13729        NaN           NaN          NaN        NaN        NaN\n",
       "13730        NaN           NaN          NaN        NaN        NaN\n",
       "13731        NaN           NaN          NaN        NaN        NaN\n",
       "13732        0.0           0.0          0.0        0.0        0.0\n",
       "13733        NaN           NaN          NaN        NaN        NaN\n",
       "\n",
       "[13734 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation\n",
    "### 1. missing value validation \n",
    "### 2. data type validation\n",
    "### 3. data range validation (similar to check outliers, I willl find another method to check outliers)\n",
    "\n",
    "Parsing refers to converting data to a specific data.\n",
    "Validation refers to checking if a given input is of a certain type type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alon_week has 8726 missing value(s)\n",
      "alon_wend has 8884 missing value(s)\n",
      "anx_band_15 has 8431 missing value(s)\n",
      "child_bull has 8745 missing value(s)\n",
      "comp_week has 8723 missing value(s)\n",
      "comp_wend has 8895 missing value(s)\n",
      "dep_band_15 has 8435 missing value(s)\n",
      "draw_week has 8722 missing value(s)\n",
      "draw_wend has 8892 missing value(s)\n",
      "exercise has 8763 missing value(s)\n",
      "height_16 has 8370 missing value(s)\n",
      "musi_week has 8731 missing value(s)\n",
      "musi_wend has 8903 missing value(s)\n",
      "out_sum_week has 8720 missing value(s)\n",
      "out_sum_wend has 8912 missing value(s)\n",
      "out_win_week has 8727 missing value(s)\n",
      "out_win_wend has 8885 missing value(s)\n",
      "play_week has 8719 missing value(s)\n",
      "play_wend has 8884 missing value(s)\n",
      "read_week has 8741 missing value(s)\n",
      "read_wend has 8900 missing value(s)\n",
      "talk_mob_week has 8718 missing value(s)\n",
      "talk_mob_wend has 8900 missing value(s)\n",
      "talk_phon_week has 8735 missing value(s)\n",
      "talk_phon_wend has 8884 missing value(s)\n",
      "text_wend has 8893 missing value(s)\n",
      "tran_week has 8710 missing value(s)\n",
      "tran_wend has 8873 missing value(s)\n",
      "tv_week has 8714 missing value(s)\n",
      "tv_wend has 8881 missing value(s)\n",
      "weight_16 has 8383 missing value(s)\n",
      "work_week has 8722 missing value(s)\n",
      "work_wend has 8901 missing value(s)\n"
     ]
    }
   ],
   "source": [
    "def check_missing_data(df):\n",
    "    for col in df.columns:\n",
    "        miss = df[col].isnull().sum()\n",
    "        if miss>0:\n",
    "            print(\"{} has {} missing value(s)\".format(col,miss))\n",
    "        else:\n",
    "            print(\"{} has NO missing value!\".format(col))\n",
    "\n",
    "check_missing_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_schema\n",
    "from pandas_schema import Column\n",
    "from pandas_schema.validation import CustomElementValidation\n",
    "import numpy as np\n",
    "from decimal import *\n",
    "\n",
    "def check_decimal(dec):\n",
    "    try:\n",
    "        Decimal(dec)\n",
    "    except InvalidOperation:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def check_int(num):\n",
    "    try:\n",
    "        int(num)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_float(num):\n",
    "    try:\n",
    "        float(num)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_nan(num):\n",
    "    try:\n",
    "        np.isnan(num)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# define validation elements\n",
    "decimal_validation = [CustomElementValidation(lambda d: check_decimal(d), 'is not decimal')]\n",
    "int_validation = [CustomElementValidation(lambda i: check_int(i), 'is not integer')]\n",
    "float_validation = [CustomElementValidation(lambda i: check_float(i), 'is not float')]\n",
    "null_validation = [CustomElementValidation(lambda d: pd.notnull(d), 'this field cannot be null')]\n",
    "\n",
    "\n",
    "# validation for 16_age_varaibles\n",
    "def do_X_validation(data):\n",
    "    \n",
    "    # define validation schema\n",
    "    schema = pandas_schema.Schema([\n",
    "            Column('alon_week', decimal_validation + null_validation),\n",
    "            Column('alon_wend', decimal_validation + null_validation),\n",
    "            Column('anx_band_15', decimal_validation + null_validation),\n",
    "            Column('child_bull', decimal_validation + null_validation),\n",
    "            Column('comp_week', decimal_validation + null_validation),\n",
    "            Column('comp_wend', decimal_validation + null_validation),\n",
    "            Column('dep_band_15', decimal_validation + null_validation),\n",
    "            Column('draw_week', decimal_validation + null_validation),\n",
    "            Column('draw_wend', decimal_validation + null_validation),\n",
    "            Column('exercise', decimal_validation + null_validation),           \n",
    "            Column('musi_week', decimal_validation + null_validation),\n",
    "            Column('musi_wend', decimal_validation + null_validation),\n",
    "            Column('out_sum_week', decimal_validation + null_validation),\n",
    "            Column('out_sum_wend', decimal_validation + null_validation),\n",
    "            Column('out_win_week', decimal_validation + null_validation),\n",
    "            Column('out_win_wend', decimal_validation + null_validation),\n",
    "            Column('play_week', decimal_validation + null_validation),\n",
    "            Column('play_wend', decimal_validation + null_validation),\n",
    "            Column('read_week', decimal_validation + null_validation),\n",
    "            Column('read_wend', decimal_validation + null_validation),\n",
    "            Column('talk_mob_week', decimal_validation + null_validation),\n",
    "            Column('talk_mob_wend', decimal_validation + null_validation),\n",
    "            Column('talk_phon_week', decimal_validation + null_validation),\n",
    "            Column('talk_phon_wend', decimal_validation + null_validation),\n",
    "            Column('text_wend', decimal_validation + null_validation),\n",
    "            Column('tran_week', decimal_validation + null_validation),\n",
    "            Column('tran_wend', decimal_validation + null_validation),\n",
    "            Column('tv_week', decimal_validation + null_validation),\n",
    "            Column('tv_wend', decimal_validation + null_validation),\n",
    "            Column('work_week', decimal_validation + null_validation),\n",
    "            Column('work_wend',  decimal_validation + null_validation),\n",
    "\n",
    "            Column('weight_16',decimal_validation + null_validation),\n",
    "            Column('height_16', decimal_validation + null_validation)])\n",
    "    \n",
    "    # apply validation\n",
    "    errors_X = schema.validate(data)\n",
    "    errors_index_rows_X = [e.row for e in errors_X]\n",
    "    data_clean_X = data.drop(index=errors_index_rows_X)\n",
    "\n",
    "    # save data\n",
    "    pd.DataFrame({'col':errors_X}).to_csv('errors_X.csv')\n",
    "    data_clean_X.to_csv('clean_X_data.csv')\n",
    "\n",
    "do_X_validation(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dep_score', 'has_dep_diag', 'panic_score', 'prim_diag', 'secd_diag'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dep_score       float64\n",
       "has_dep_diag    float64\n",
       "panic_score     float64\n",
       "prim_diag       float64\n",
       "secd_diag       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation for 18_age_variables\n",
    "def do_Y_validation(data):\n",
    "    schema = pandas_schema.Schema([\n",
    "        Column('dep_score', decimal_validation + null_validation),\n",
    "        Column('has_dep_diag', decimal_validation + null_validation),\n",
    "        Column('prim_diag', decimal_validation + null_validation),\n",
    "        Column('secd_diag', decimal_validation + null_validation),\n",
    "        Column('work_wend',  decimal_validation + null_validation)\n",
    "    ])\n",
    "    \n",
    "    # apply validation\n",
    "    errors_Y = schema.validate(data)\n",
    "    errors_index_rows_Y = [e.row for e in errors_Y]\n",
    "    \n",
    "    # filter index >= 0\n",
    "    errors_index_rows_Y = list(filter(lambda errors_index_rows_Y: errors_index_rows_Y >= 0, errors_index_rows_Y))\n",
    "    data_clean_Y = data.drop(index=errors_index_rows_Y)\n",
    "\n",
    "    # save data\n",
    "    pd.DataFrame({'col':errors_Y}).to_csv('errors_Y.csv')\n",
    "    data_clean_Y.to_csv('clean_Y_data.csv')\n",
    "\n",
    "do_Y_validation(Y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
