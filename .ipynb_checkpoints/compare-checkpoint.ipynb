{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from collections import Counter\n",
    "from itertools import chain, combinations\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we compare the performance of multiple models on different subsets of our data.\n",
    "#### The models are:\n",
    "+ Logistic Regression\n",
    "+ SVM\n",
    "+ KNN\n",
    "+ Neural Network\n",
    "+ XGBoost\n",
    "\n",
    "#### The datasets:\n",
    "+ Mean/Mode imputed\n",
    "+ KNN imputed\n",
    "+ MICE imputed\n",
    "+ no imputations\n",
    "\n",
    "#### The targets:\n",
    "+ has_dep_diag\n",
    "+ a binary combination of all the target variables\n",
    "\n",
    "#### In combinations of:\n",
    "+ trained on balanced, tested on balanced\n",
    "+ trained on balanced, tested on imbalanced\n",
    "+ trained on imbalanced, tested on balanced\n",
    "+ trained on imbalanced, tested on imbalanced\n",
    "\n",
    "#### We employ  range of visualisation methods:\n",
    "+ ROC curves\n",
    "+ bar plots\n",
    "+ learning curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iputed datasets:\n",
    "+ 0 - unedited\n",
    "+ 1 - Mean/Mode\n",
    "+ 2/3? - drop NaN\n",
    "+ 4 - K-Means\n",
    "+ 5 - MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = pd.read_csv(\"newdata3.csv\", engine='python')\n",
    "data1 = pd.read_csv(\"imputed_dataset_1.csv\", engine='python').drop(['Unnamed: 0'], axis = 1)\n",
    "data2 = pd.read_csv(\"imputed_dataset_2.csv\", engine='python').drop(['Unnamed: 0'], axis = 1)\n",
    "data3 = pd.read_csv(\"imputed_dataset_3.csv\", engine='python').drop(['Unnamed: 0'], axis = 1)\n",
    "data4 = pd.read_csv(\"imputed_dataset_4.csv\", engine='python').drop(['Unnamed: 0'], axis = 1)\n",
    "data5 = pd.read_csv(\"imputed_dataset_5.csv\", engine='python').drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset 5 - combined variable (dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"imputed_dataset_5.csv\", engine='python').drop(['Unnamed: 0'], axis = 1)\n",
    "dep_data = data.copy()\n",
    "\n",
    "dep_num = np.array([12, 11, 10, 4])\n",
    "no_dep_num = np.setdiff1d(range(13), dep_num)\n",
    "\n",
    "dep_data[['prim_diag', 'secd_diag']] = dep_data[['prim_diag', 'secd_diag']].replace(list(no_dep_num), 0)\n",
    "dep_data[['prim_diag', 'secd_diag']] = dep_data[['prim_diag', 'secd_diag']].replace(list(dep_num), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = data.dropna(axis = 0, how = 'any')\n",
    "dep = [x for x in data.columns if 'dep' in x or 'diag' in x or 'panic' in x]\n",
    "dep_data['dep'] = dep_data['secd_diag'] + dep_data['prim_diag'] + 0 * dep_data['has_dep_diag']\n",
    "dep_data['dep'] = dep_data['dep'].replace(range(2, 4), 1)\n",
    "full = dep_data.dropna(axis = 0, how = 'any')\n",
    "dep = [x for x in data.columns if 'dep' in x or 'diag' in x or 'panic' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_dep = full.query('dep == 1')\n",
    "no_dep = full.query('dep == 0')\n",
    "size = int(np.round(0.8 * min(len(has_dep), len(no_dep))))\n",
    "#sample = pd.concat([has_dep.sample(size), no_dep.sample(size)])\n",
    "sample = full.sample(8000)\n",
    "\n",
    "sample = sample.sort_index()\n",
    "sample = sample.reset_index(drop = True)\n",
    "\n",
    "\n",
    "X_comb = sample.drop(dep, axis = 1).drop('dep', axis = 1)\n",
    "Y_comb = sample['dep']\n",
    "\n",
    "#sample = full.sample(8000)\n",
    "#smote = SMOTE(random_state = 0)\n",
    "#X, y = smote.fit_resample(sample.drop(dep, axis = 1).drop('dep', axis = 1), sample['dep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset 5 - has_dep_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13734, 36)\n",
      "(13734,)\n"
     ]
    }
   ],
   "source": [
    "X_hasdep = data5.drop(['has_dep_diag'],axis=1).drop(['secd_diag'],axis=1).drop(['prim_diag'],axis=1).drop(['dep_score'],axis=1).drop(['dep_thoughts'],axis=1).drop(['panic_score'], axis=1)\n",
    "print(X.shape)\n",
    "Y_hasdep = np.array(data5['has_dep_diag'])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over/undersampling to obtain imbalanced and balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state = 0)\n",
    "\n",
    "#combined, imbalanced (original ratio), undersampling\n",
    "X_combined_imb_und, y_combained_imb_und = smote.fit_resample(sample.drop(dep, axis = 1).drop('dep', axis = 1), sample['dep'])\n",
    "#combined, imbalanced (original ratio), oversampling\n",
    "#combined, balanced, undersampling\n",
    "#combined, balanced, oversampling\n",
    "#has_dep_diag, imbalanced (original ratio), undersampling\n",
    "#has_dep_diag, imbalanced (original ratio), oversampling\n",
    "#has_dep_diag, balanced, undersampling\n",
    "#has_dep_diag, balanced, oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def shuffle_dataset(N, X, y, X_shuffled, y_shuffled):\n",
    "    ind_list = [i for i in range(N)]\n",
    "    shuffle(ind_list)\n",
    "    X_shuffled  = X.iloc[ind_list]\n",
    "    y_shuffled = y.iloc[ind_list]\n",
    "    \n",
    "def split_dataset(split, N, X, y):\n",
    "    X_shuffled = X\n",
    "    y_shuffled = y\n",
    "    shuffle_dataset(N, pd. DataFrame(X), pd. DataFrame(Y), pd. DataFrame(X_shuffled), pd. DataFrame(y_shuffled))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled,test_size=split, random_state=40)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 35)\n",
      "(1600, 35)\n",
      "(6400,)\n",
      "(1600,)\n"
     ]
    }
   ],
   "source": [
    "X_train_a, X_test_a, y_train_a, y_test_a = split_dataset(0.2, Y_comb.size, X_comb, Y_comb)\n",
    "print(X_train_a.shape); print(X_test_a.shape)\n",
    "print(y_train_a.shape); print(y_test_a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
